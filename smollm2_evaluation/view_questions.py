#!/usr/bin/env python3
"""
æŸ¥çœ‹è¯„ä¼°é¢˜ç›®çš„å®ç”¨å·¥å…·

ç”¨æ³•:
    python view_questions.py hellaswag 5         # æŸ¥çœ‹ 5 ä¸ª HellaSwag é¢˜ç›®
    python view_questions.py arc_challenge 3     # æŸ¥çœ‹ 3 ä¸ª ARC-Challenge é¢˜ç›®
    python view_questions.py mmlu_anatomy 10     # æŸ¥çœ‹ 10 ä¸ª MMLU anatomy é¢˜ç›®
"""

import json
import sys
import glob
import random
from pathlib import Path

def format_question(data, index=None):
    """æ ¼å¼åŒ–è¾“å‡ºä¸€ä¸ªé¢˜ç›®"""
    doc = data['doc']
    target = int(data['target'])
    
    # æ¨¡å‹ç­”æ¡ˆ
    scores = [s[0] for s in data['filtered_resps']]
    model_answer = scores.index(max(scores))
    is_correct = model_answer == target
    
    # åˆ†éš”çº¿
    print("\n" + "="*70)
    if index is not None:
        print(f"é¢˜ç›® #{index}")
    print("="*70)
    
    # æ ¹æ®ä¸åŒæ•°æ®é›†æ ¼å¼æ˜¾ç¤ºé¢˜ç›®
    if 'query' in doc:  # HellaSwag
        print(f"ğŸ“ æƒ…å¢ƒ: {doc.get('activity_label', '')}")
        print(f"   {doc['query']}")
        print(f"\nğŸ“‹ é€‰é¡¹:")
        for i, ending in enumerate(doc['endings']):
            marker = "âœ“" if i == target else " "
            model_marker = "ğŸ¤–" if i == model_answer else "  "
            print(f"   {model_marker} [{i}] {ending} {marker}")
    
    elif 'question' in doc:  # ARC, OpenBookQA, MMLU
        print(f"ğŸ“ é—®é¢˜: {doc['question']}")
        
        if 'choices' in doc and isinstance(doc['choices'], dict):
            print(f"\nğŸ“‹ é€‰é¡¹:")
            for i, choice in enumerate(doc['choices']['text']):
                label = doc['choices']['label'][i]
                marker = "âœ“" if i == target else " "
                model_marker = "ğŸ¤–" if i == model_answer else "  "
                print(f"   {model_marker} [{label}] {choice} {marker}")
        elif 'choices' in doc and isinstance(doc['choices'], list):
            print(f"\nğŸ“‹ é€‰é¡¹:")
            for i, choice in enumerate(doc['choices']):
                marker = "âœ“" if i == target else " "
                model_marker = "ğŸ¤–" if i == model_answer else "  "
                print(f"   {model_marker} [{i}] {choice} {marker}")
    
    elif 'sentence' in doc:  # WinoGrande
        print(f"ğŸ“ å¥å­: {doc['sentence']}")
        print(f"\nğŸ“‹ é€‰é¡¹:")
        if 'option1' in doc and 'option2' in doc:
            options = [doc['option1'], doc['option2']]
            for i, option in enumerate(options):
                marker = "âœ“" if i == target else " "
                model_marker = "ğŸ¤–" if i == model_answer else "  "
                print(f"   {model_marker} [{i}] {option} {marker}")
    
    elif 'passage' in doc:  # BoolQ
        print(f"ğŸ“ æ®µè½: {doc['passage'][:200]}..." if len(doc.get('passage', '')) > 200 else f"ğŸ“ æ®µè½: {doc.get('passage', '')}")
        print(f"   é—®é¢˜: {doc.get('question', '')}")
        print(f"\nğŸ“‹ ç­”æ¡ˆ:")
        options = ['False', 'True']
        for i, option in enumerate(options):
            marker = "âœ“" if i == target else " "
            model_marker = "ğŸ¤–" if i == model_answer else "  "
            print(f"   {model_marker} [{i}] {option} {marker}")
    
    else:
        print(f"ğŸ“ é¢˜ç›®æ•°æ®: {doc}")
    
    # æ˜¾ç¤ºç»“æœ
    formatted_scores = [f'{float(s):.2f}' if isinstance(s, (int, float)) else str(s) for s in scores]
    print(f"\nğŸ“Š æ¨¡å‹åˆ†æ•°: {formatted_scores}")
    print(f"âœ… æ­£ç¡®ç­”æ¡ˆ: {target}")
    print(f"ğŸ¤– æ¨¡å‹ç­”æ¡ˆ: {model_answer}")
    
    if is_correct:
        print(f"ğŸ‰ ç»“æœ: âœ… ç­”å¯¹äº†ï¼")
    else:
        print(f"âŒ ç»“æœ: ç­”é”™äº†")
    
    print("="*70)

def find_sample_file(task_name, results_dir):
    """æŸ¥æ‰¾æ ·æœ¬æ–‡ä»¶"""
    pattern = f"{results_dir}/*/samples_{task_name}_*.jsonl"
    files = glob.glob(pattern)
    
    if not files:
        # å°è¯•ä¸åŒçš„ç›®å½•ç»“æ„
        pattern = f"{results_dir}/samples_{task_name}_*.jsonl"
        files = glob.glob(pattern)
    
    if files:
        return files[0]
    return None

def view_questions(task_name, num_questions=5, random_sample=True, results_dir=None):
    """æŸ¥çœ‹æŒ‡å®šä»»åŠ¡çš„é¢˜ç›®"""
    
    # é»˜è®¤ç»“æœç›®å½•
    if results_dir is None:
        results_dir = "results/step-125000"
    
    # æŸ¥æ‰¾æ ·æœ¬æ–‡ä»¶
    sample_file = find_sample_file(task_name, results_dir)
    
    if not sample_file:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ä»»åŠ¡ '{task_name}' çš„æ ·æœ¬æ–‡ä»¶")
        print(f"\nå¯ç”¨çš„ä»»åŠ¡:")
        
        # åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä»»åŠ¡
        pattern = f"{results_dir}/*/samples_*.jsonl"
        files = glob.glob(pattern)
        if not files:
            pattern = f"{results_dir}/samples_*.jsonl"
            files = glob.glob(pattern)
        
        tasks = set()
        for f in files:
            name = Path(f).name
            # æå–ä»»åŠ¡å: samples_TASKNAME_timestamp.jsonl
            if name.startswith('samples_'):
                task = name.replace('samples_', '').rsplit('_', 1)[0]
                tasks.add(task)
        
        for task in sorted(tasks):
            print(f"  - {task}")
        
        return
    
    print(f"\nğŸ“ æ–‡ä»¶: {sample_file}")
    
    # è¯»å–æ‰€æœ‰é¢˜ç›®
    questions = []
    with open(sample_file, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                questions.append(json.loads(line))
            except:
                continue
    
    total = len(questions)
    print(f"ğŸ“Š æ€»å…± {total} ä¸ªé¢˜ç›®")
    
    # é€‰æ‹©è¦æ˜¾ç¤ºçš„é¢˜ç›®
    if random_sample and num_questions < total:
        selected = random.sample(questions, num_questions)
        print(f"ğŸ² éšæœºé€‰æ‹© {num_questions} ä¸ªé¢˜ç›®:")
    else:
        selected = questions[:num_questions]
        print(f"ğŸ“– æ˜¾ç¤ºå‰ {num_questions} ä¸ªé¢˜ç›®:")
    
    # æ˜¾ç¤ºé¢˜ç›®
    for i, q in enumerate(selected, 1):
        format_question(q, index=i)

def show_statistics(task_name, results_dir=None):
    """æ˜¾ç¤ºä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯"""
    
    if results_dir is None:
        results_dir = "results/step-125000"
    
    sample_file = find_sample_file(task_name, results_dir)
    
    if not sample_file:
        print(f"âŒ æ‰¾ä¸åˆ°ä»»åŠ¡ '{task_name}' çš„æ ·æœ¬æ–‡ä»¶")
        return
    
    correct = 0
    total = 0
    
    with open(sample_file, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data = json.loads(line)
                total += 1
                
                scores = [s[0] for s in data['filtered_resps']]
                model_answer = scores.index(max(scores))
                correct_answer = int(data['target'])
                
                if model_answer == correct_answer:
                    correct += 1
            except:
                continue
    
    accuracy = correct / total if total > 0 else 0
    
    print(f"\n{'='*70}")
    print(f"ğŸ“Š ä»»åŠ¡ç»Ÿè®¡: {task_name}")
    print(f"{'='*70}")
    print(f"æ€»é¢˜ç›®æ•°: {total}")
    print(f"ç­”å¯¹æ•°é‡: {correct}")
    print(f"ç­”é”™æ•°é‡: {total - correct}")
    print(f"å‡†ç¡®ç‡: {accuracy:.2%}")
    print(f"{'='*70}\n")

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  python view_questions.py <ä»»åŠ¡å> [æ•°é‡] [--stats]")
        print("")
        print("ç¤ºä¾‹:")
        print("  python view_questions.py hellaswag 5")
        print("  python view_questions.py arc_challenge 3")
        print("  python view_questions.py mmlu_anatomy 10")
        print("  python view_questions.py hellaswag --stats")
        print("")
        print("å¯ç”¨ä»»åŠ¡:")
        
        # åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä»»åŠ¡
        results_dir = "results/step-125000"
        pattern = f"{results_dir}/*/samples_*.jsonl"
        files = glob.glob(pattern)
        if not files:
            pattern = f"{results_dir}/samples_*.jsonl"
            files = glob.glob(pattern)
        
        tasks = set()
        for f in files:
            name = Path(f).name
            if name.startswith('samples_'):
                task = name.replace('samples_', '').rsplit('_', 1)[0]
                tasks.add(task)
        
        for task in sorted(tasks):
            print(f"  - {task}")
        
        return
    
    task_name = sys.argv[1]
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ç»Ÿè®¡æ¨¡å¼
    if '--stats' in sys.argv:
        show_statistics(task_name)
        return
    
    num_questions = 5
    if len(sys.argv) >= 3 and sys.argv[2].isdigit():
        num_questions = int(sys.argv[2])
    
    view_questions(task_name, num_questions)

if __name__ == "__main__":
    main()

